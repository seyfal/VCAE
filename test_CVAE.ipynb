{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder dimensions: [(1, 40, 40, 200), (32, 20, 20, 100), (64, 10, 10, 50), (128, 5, 5, 50)]\n",
      "Decoder dimensions: [(128, 5, 5, 50), (64, 10, 10, 100), (32, 20, 20, 200), (1, 40, 40, 200)]\n",
      "FlexibleCVAE3D(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=160000, out_features=512, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=160000, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Unflatten(dim=1, unflattened_size=(128, 5, 5, 50))\n",
      "    (5): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (6): ReLU()\n",
      "    (7): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (8): ReLU()\n",
      "    (9): ConvTranspose3d(32, 1, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "  )\n",
      ")\n",
      "Input shape: torch.Size([1, 1, 40, 40, 200])\n",
      "After 0: torch.Size([1, 32, 20, 20, 100])\n",
      "After 1: torch.Size([1, 32, 20, 20, 100])\n",
      "After 2: torch.Size([1, 64, 10, 10, 50])\n",
      "After 3: torch.Size([1, 64, 10, 10, 50])\n",
      "After 4: torch.Size([1, 128, 5, 5, 25])\n",
      "After 5: torch.Size([1, 128, 5, 5, 25])\n",
      "After 6: torch.Size([1, 80000])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x80000 and 160000x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 115\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Debug: print shapes at each layer\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[0;32m--> 115\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m output, mu, logvar \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39minput_shape))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1730\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x80000 and 160000x512)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class FlexibleCVAE3D(nn.Module):\n",
    "    def __init__(self, input_shape, latent_dim, conv_layers=3, fc_layers=2):\n",
    "        super(FlexibleCVAE3D, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_dim = latent_dim\n",
    "        self.conv_layers = conv_layers\n",
    "        self.fc_layers = fc_layers\n",
    "\n",
    "        # Calculate dimensions for each layer\n",
    "        self.encoder_dims = self.calculate_encoder_dims()\n",
    "        self.decoder_dims = self.calculate_decoder_dims()\n",
    "\n",
    "        # Build encoder\n",
    "        self.encoder = self.build_encoder()\n",
    "        \n",
    "        # Build decoder\n",
    "        self.decoder = self.build_decoder()\n",
    "\n",
    "        print(\"Encoder dimensions:\", self.encoder_dims)\n",
    "        print(\"Decoder dimensions:\", self.decoder_dims)\n",
    "\n",
    "    def calculate_encoder_dims(self):\n",
    "        dims = [self.input_shape]\n",
    "        channels = [1, 32, 64, 128]  # You can adjust this list as needed\n",
    "        for i in range(self.conv_layers):\n",
    "            h = dims[-1][1] // 2\n",
    "            w = dims[-1][2] // 2\n",
    "            d = dims[-1][3] // 2 if i < 2 else dims[-1][3]  # Only reduce depth in first two layers\n",
    "            c = channels[i+1] if i+1 < len(channels) else channels[-1]\n",
    "            dims.append((c, h, w, d))\n",
    "        return dims\n",
    "\n",
    "    def calculate_decoder_dims(self):\n",
    "        dims = self.encoder_dims[::-1]\n",
    "        for i in range(len(dims) - 1):\n",
    "            dims[i+1] = (dims[i+1][0], dims[i][1] * 2, dims[i][2] * 2, dims[i][3] * 2 if i < 2 else dims[i][3])\n",
    "        return dims\n",
    "\n",
    "    def build_encoder(self):\n",
    "        layers = []\n",
    "        for i in range(self.conv_layers):\n",
    "            layers.append(nn.Conv3d(self.encoder_dims[i][0], self.encoder_dims[i+1][0], kernel_size=3, stride=2, padding=1))\n",
    "            layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Flatten())\n",
    "        \n",
    "        fc_input_dim = math.prod(self.encoder_dims[-1])\n",
    "        fc_dims = [fc_input_dim] + [512] * (self.fc_layers - 1) + [self.latent_dim * 2]\n",
    "        \n",
    "        for i in range(self.fc_layers):\n",
    "            layers.append(nn.Linear(fc_dims[i], fc_dims[i+1]))\n",
    "            if i < self.fc_layers - 1:\n",
    "                layers.append(nn.ReLU())\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def build_decoder(self):\n",
    "        layers = []\n",
    "        \n",
    "        fc_output_dim = math.prod(self.decoder_dims[0])\n",
    "        fc_dims = [self.latent_dim] + [512] * (self.fc_layers - 1) + [fc_output_dim]\n",
    "        \n",
    "        for i in range(self.fc_layers):\n",
    "            layers.append(nn.Linear(fc_dims[i], fc_dims[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Unflatten(1, self.decoder_dims[0]))\n",
    "        \n",
    "        for i in range(self.conv_layers - 1):\n",
    "            layers.append(nn.ConvTranspose3d(self.decoder_dims[i][0], self.decoder_dims[i+1][0], \n",
    "                                             kernel_size=3, stride=2, padding=1, output_padding=1))\n",
    "            layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.ConvTranspose3d(self.decoder_dims[-2][0], self.decoder_dims[-1][0], \n",
    "                                         kernel_size=3, stride=2, padding=1, output_padding=1))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return torch.chunk(h, 2, dim=1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "# Usage example\n",
    "input_shape = (1, 40, 40, 200)  # (channels, height, width, depth)\n",
    "latent_dim = 256\n",
    "model = FlexibleCVAE3D(input_shape, latent_dim)\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Example forward pass\n",
    "x = torch.randn(1, *input_shape)\n",
    "print(\"Input shape:\", x.shape)\n",
    "\n",
    "# Debug: print shapes at each layer\n",
    "for name, layer in model.encoder.named_children():\n",
    "    x = layer(x)\n",
    "    print(f\"After {name}: {x.shape}\")\n",
    "\n",
    "output, mu, logvar = model(torch.randn(1, *input_shape))\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Mu shape: {mu.shape}\")\n",
    "print(f\"Logvar shape: {logvar.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
